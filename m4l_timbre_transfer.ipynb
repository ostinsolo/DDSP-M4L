{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NkMl1mjCOpdl"
      },
      "source": [
        "# M4L - Timbre Transfer \n",
        "\n",
        "\"Have fun! And please feel free to hack this notebook to make your own creative interactions.“[- Magenta](https://colab.research.google.com/github/magenta/ddsp/blob/master/ddsp/colab/demos/timbre_transfer.ipynb)\n",
        "\n",
        "This is such a hacked notebook. It contains a loop that searches a Google Drive folder for new files to process, and have a m4l-devices for settings and download of processed files.\n",
        "\n",
        "### Instructions for running:\n",
        "\n",
        "* Make sure to use a GPU runtime, click:  __Runtime >> Change Runtime Type >> GPU__\n",
        "* Press ▶️ on the left of each of the cells\n",
        "* View the code: Double-click any of the cells\n",
        "* Hide the code: Double click the right side of the cell\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6GpXRuXAe5Mg"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "poW2zrzh3_h_"
      },
      "outputs": [],
      "source": [
        "#@title Install and Import\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package])\n",
        "\n",
        "print('Installing and upgrading packages...')\n",
        "\n",
        "# List of packages to install/upgrade\n",
        "packages = [\n",
        "    \"pip==23.3.1\",\n",
        "    \"numpy==1.24.3\",\n",
        "    \"scipy\",\n",
        "    \"matplotlib\",\n",
        "    \"librosa==0.9.2\",\n",
        "    \"pydub\",\n",
        "    \"google-auth-oauthlib==0.4.6\",\n",
        "    \"pydrive\",\n",
        "    \"protobuf==3.20.0\",\n",
        "    \"tensorflow==2.12.0\",\n",
        "    \"tensorflow-probability==0.19.0\",\n",
        "    \"crepe\",\n",
        "    \"ddsp\"\n",
        "]\n",
        "\n",
        "# Install packages\n",
        "for package in packages:\n",
        "    install(package)\n",
        "\n",
        "# Reload the sys module to ensure we're using the newly installed packages\n",
        "import importlib\n",
        "importlib.reload(sys)\n",
        "\n",
        "# Ignore deprecation warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Import required modules\n",
        "import copy\n",
        "import os\n",
        "import time \n",
        "import json\n",
        "import crepe\n",
        "import ddsp\n",
        "import ddsp.training\n",
        "from ddsp.colab import colab_utils\n",
        "from ddsp.colab.colab_utils import (\n",
        "    auto_tune, get_tuning_factor, play, record, \n",
        "    specplot, upload, DEFAULT_SAMPLE_RATE\n",
        ")\n",
        "from ddsp.training import postprocessing\n",
        "detect_notes = postprocessing.detect_notes\n",
        "fit_quantile_transform = postprocessing.fit_quantile_transform\n",
        "\n",
        "import gin\n",
        "from google.colab import files\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Helper Functions\n",
        "sample_rate = DEFAULT_SAMPLE_RATE  # 16000\n",
        "\n",
        "import base64\n",
        "import io\n",
        "import tempfile\n",
        "import pickle\n",
        "\n",
        "from IPython import display\n",
        "from pydub import AudioSegment\n",
        "from scipy.io import wavfile\n",
        "\n",
        "from google.colab import output\n",
        "from google.colab import files as colab_files\n",
        "download = colab_files.download\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "# Verify installations\n",
        "installed_packages = pkg_resources.working_set\n",
        "installed_packages_list = sorted([f\"{i.key}=={i.version}\" for i in installed_packages])\n",
        "print(\"Installed packages:\")\n",
        "for package in installed_packages_list:\n",
        "    print(package)\n",
        "\n",
        "# Print DDSP version\n",
        "print(f\"DDSP version: {ddsp.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EEKrh62Ee96P"
      },
      "source": [
        "##Login for authentication for Google Drive access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9Xrd_SF74WH0"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "suhegPgv6CnN"
      },
      "source": [
        "\n",
        "# Load functionality from DDSP 'Timbre Transfer Demo Notebook'\n",
        "\n",
        "Essentially copy/paste from the DDSP 'Timbre Transfer Demo Notebook', made to work for this. Added functions for file management. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "_McEN8UT4WEh"
      },
      "outputs": [],
      "source": [
        "#@title Whole lotta code\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "gdID = None\n",
        "file_list = drive.ListFile({'q': \"'root' in parents and trashed=false and title = 'M4L-Timbre-Transfer-Folder'\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "  gdID = file1['id']\n",
        "\n",
        "audio = None\n",
        "audio_features = None\n",
        "audio_features_mod = None\n",
        "def p4load(fileName):\n",
        "  global audio, audio_features, audio_features_mod\n",
        "  anp, sr = load_audio(fileName)\n",
        "  print(\"anp\", anp)\n",
        "  audio = anp[np.newaxis, :]\n",
        "  specplot(audio)\n",
        "  play(audio)\n",
        "\n",
        "  # Setup the session.\n",
        "  ddsp.spectral_ops.reset_crepe()\n",
        "\n",
        "  start_time = time.time()\n",
        "  audio_features = ddsp.training.metrics.compute_audio_features(audio)\n",
        "  audio_features['loudness_db'] = audio_features['loudness_db'].numpy().astype(np.float32)\n",
        "  audio_features_mod = None\n",
        "  print('Audio features took %.1f seconds' % (time.time() - start_time))\n",
        "\n",
        "TRIM = -15\n",
        "\n",
        "def load_audio(path):\n",
        "    audio_np, unused_sr = librosa.core.load(path, sr=16000)\n",
        "    return audio_np.astype(np.float32), unused_sr\n",
        "\n",
        "# The rest of your code remains unchanged\n",
        "def p4model(m):\n",
        "    global audio_features_mod, audio, audio_features\n",
        "    global model, MODEL\n",
        "    model = m\n",
        "    MODEL = m\n",
        "    GCS_CKPT_DIR = 'gs://ddsp/models/tf2'\n",
        "    print(\"m\", m, \"model\", model, \"MODEL\", MODEL)\n",
        "    if model in ('Violin', 'Flute', 'Flute2', 'Trumpet', 'Tenor_Saxophone'):\n",
        "        # Pretrained models.\n",
        "        PRETRAINED_DIR = '/content/pretrained'\n",
        "        # Copy over from gs:// for faster loading.\n",
        "        !rm -r $PRETRAINED_DIR &> /dev/null\n",
        "        !mkdir $PRETRAINED_DIR &> /dev/null\n",
        "        GCS_CKPT_DIR = 'gs://ddsp/models/tf2'\n",
        "        model_dir = os.path.join(GCS_CKPT_DIR, 'solo_%s_ckpt' % model.lower())\n",
        "        \n",
        "        !gsutil cp $model_dir/* $PRETRAINED_DIR &> /dev/null\n",
        "        model_dir = PRETRAINED_DIR\n",
        "        gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n",
        "\n",
        "    # Load the dataset statistics.\n",
        "    DATASET_STATS = None\n",
        "    dataset_stats_file = os.path.join(model_dir, 'dataset_statistics.pkl')\n",
        "    print(f'Loading dataset statistics from {dataset_stats_file}')\n",
        "    try:\n",
        "      if tf.io.gfile.exists(dataset_stats_file):\n",
        "        with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
        "          DATASET_STATS = pickle.load(f)\n",
        "    except Exception as err:\n",
        "      print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
        "\n",
        "    # Parse gin config,\n",
        "    with gin.unlock_config():\n",
        "      gin.parse_config_file(gin_file, skip_unknown=True)\n",
        "    \n",
        "    # Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
        "    ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if 'ckpt' in f]\n",
        "    ckpt_name = ckpt_files[0].split('.')[0]\n",
        "    ckpt = os.path.join(model_dir, ckpt_name)\n",
        "    \n",
        "    # Ensure dimensions and sampling rates are equal\n",
        "    time_steps_train = gin.query_parameter('DefaultPreprocessor.time_steps')\n",
        "    n_samples_train = gin.query_parameter('Additive.n_samples')\n",
        "    hop_size = int(n_samples_train / time_steps_train)\n",
        "    \n",
        "    time_steps = int(audio.shape[1] / hop_size)\n",
        "    n_samples = time_steps * hop_size\n",
        "    \n",
        "    gin_params = [\n",
        "        'RnnFcDecoder.input_keys = (\"f0_scaled\", \"ld_scaled\")',\n",
        "        'Additive.n_samples = {}'.format(n_samples),\n",
        "        'FilteredNoise.n_samples = {}'.format(n_samples),\n",
        "        'DefaultPreprocessor.time_steps = {}'.format(time_steps),\n",
        "    ]\n",
        "    \n",
        "    with gin.unlock_config():\n",
        "      gin.parse_config(gin_params)\n",
        "    \n",
        "    # Trim all input vectors to correct lengths \n",
        "    for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
        "      audio_features[key] = audio_features[key][:time_steps]\n",
        "    audio_features['audio'] = audio_features['audio'][:, :n_samples]\n",
        "    \n",
        "    # Set up the model just to predict audio given new conditioning\n",
        "    model = ddsp.training.models.Autoencoder()\n",
        "    model.restore(ckpt)\n",
        "    \n",
        "    # Build model by running a batch through it.\n",
        "    start_time = time.time()\n",
        "    _ = model(audio_features, training=False)\n",
        "    print('Restoring model took %.1f seconds' % (time.time() - start_time))\n",
        "\n",
        "print('DONE')\n",
        "\n",
        "# The rest of your functions (p4modify, create_audio_file, p4makeSave2) remain unchanged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kpO0nsqciyKk"
      },
      "source": [
        "This continously checks for new files in Google Drive, processes them, and uploaded the transferred audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "TM12QUzU5hdP"
      },
      "outputs": [],
      "source": [
        "#@title LOOP\n",
        "import time\n",
        "\n",
        "count = 0\n",
        "found = False\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        if not found:\n",
        "            # FIND JSON\n",
        "            file_list = drive.ListFile(\n",
        "                {'q': f\"'{gdID}' in parents and trashed=false and title='settings{count}.json'\"}).GetList()\n",
        "            \n",
        "            for file1 in file_list:\n",
        "                print(f'title: {file1[\"title\"]}, id: {file1[\"id\"]}')\n",
        "                downloaded = drive.CreateFile({'id': file1['id']})\n",
        "                content = downloaded.GetContentString()\n",
        "                print(f'Downloaded content \"{content}\"')\n",
        "                jf = json.loads(content)\n",
        "                print('time passed:', ((time.time()) % 86400) - jf[\"time\"])\n",
        "                found = True\n",
        "                break  # Exit the loop after processing the first file\n",
        "\n",
        "        if found:\n",
        "            # LOAD AUDIO\n",
        "            file_list = drive.ListFile(\n",
        "                {'q': f\"'{gdID}' in parents and trashed=false and title='sendAudio{count}.wav'\"}).GetList()\n",
        "            \n",
        "            for file1 in file_list:\n",
        "                print(f'title: {file1[\"title\"]}, id: {file1[\"id\"]}')\n",
        "                aud = drive.CreateFile({'id': file1['id']})\n",
        "                aud.GetContentFile(f\"ddsp{count}.wav\")\n",
        "                \n",
        "                p4load(f\"ddsp{count}.wav\")\n",
        "                play(audio)\n",
        "                print(f\"model from json is {jf['model']}\")\n",
        "                p4model(jf[\"model\"])\n",
        "                \n",
        "                p4modify(jf[\"octave\"], jf[\"loudness\"], jf[\"threshold\"], jf[\"auto\"], jf[\"autotune\"], jf[\"quiet\"])\n",
        "                \n",
        "                p4makeSave2(f\"audio-transferred{count}.wav\")\n",
        "                count += 1\n",
        "                found = False\n",
        "                break  # Exit the loop after processing the first file\n",
        "\n",
        "        # Sleep for a short time to avoid excessive API calls\n",
        "        time.sleep(5)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        time.sleep(60)  # Wait for a minute before trying again"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "m4l_timbre_transfer.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
